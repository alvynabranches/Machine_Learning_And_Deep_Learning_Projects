{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "# device = T.device('cpu')\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "classes.extend('A B C D E F G H I J K L M N O P Q R S T U V W X Y Z'.upper().split())\n",
    "classes.extend('A B C D E F G H I J K L M N O P Q R S T U V W X Y Z'.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class ConvModel(nn.Module):\n",
    "    def __init__(self, input_shape=(128, 128, 1), hidden_conv_size=[128,64,32,16], hidden_fc_size=[576, 288, 144, 144, 72], output_classes=62):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=hidden_conv_size[0], out_channels=hidden_conv_size[1], kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=hidden_conv_size[1], out_channels=hidden_conv_size[2], kernel_size=3, stride=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=hidden_conv_size[2], out_channels=hidden_conv_size[3], kernel_size=3, stride=1)\n",
    "        self.fc1 = nn.Linear(in_features=hidden_fc_size[0], out_features=hidden_fc_size[1])\n",
    "        self.fc2 = nn.Linear(in_features=hidden_fc_size[1], out_features=hidden_fc_size[2])\n",
    "        self.fc3 = nn.Linear(in_features=hidden_fc_size[3], out_features=hidden_fc_size[4])\n",
    "        self.fc4 = nn.Linear(in_features=hidden_fc_size[4], out_features=output_classes)\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1)\n",
    "        X = F.max_pool2d(X)\n",
    "        X = F.relu(self.conv2)\n",
    "        X = F.max_pool2d(X)\n",
    "        X = F.relu(self.conv3)\n",
    "        X = F.max_pool2d(X)\n",
    "\n",
    "        X = X.view(-1, 16*6*6)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = F.relu(self.fc3(X))\n",
    "\n",
    "        return F.softmax(self.fc4, dim=1)\n",
    "    def save_checkpoint(self, filename):\n",
    "        T.save(self.state_dict(), filename)\n",
    "    \n",
    "    def load_checkpoint(self, filename):\n",
    "        self.load_state_dict(T.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.02 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvModel(\n",
       "  (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=576, out_features=288, bias=True)\n",
       "  (fc2): Linear(in_features=288, out_features=144, bias=True)\n",
       "  (fc3): Linear(in_features=144, out_features=72, bias=True)\n",
       "  (fc4): Linear(in_features=72, out_features=62, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = ConvModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 992 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = T.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "l = 0\n",
    "for dirpath, _, filenames in os.walk('data/'):\n",
    "    if dirpath is not 'data/':\n",
    "        for f in filenames:\n",
    "            X.append(imread(f'{dirpath}/{f}'))\n",
    "            y.append(l)\n",
    "        l += 1\n",
    "\n",
    "X_batch, y_batch = [], []\n",
    "for i in range(0, len(X), batch_size:=100):\n",
    "    X_batch.append(np.array(X[i:i+batch_size]))\n",
    "    y_batch.append(np.array(y[i:i+batch_size]))\n",
    "\n",
    "X_new = np.array(X_batch)\n",
    "y_new = np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "print(X_new.shape)\n",
    "print(y_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.38 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 100\n",
    "X_batch, y_batch = [], []\n",
    "for i in range(0, len(X), batch_size):\n",
    "    X_batch.append(X[i:i+batch_size])\n",
    "    y_batch.append(y[i:i+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X = T.tensor(X)\n",
    "y = T.tensor(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "X_train, X_valn, y_train, y_valn = train_test_split(X_train, y_train, test_size=0.15)\n",
    "\n",
    "model.to(device)\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_valn = X_valn.to(device)\n",
    "y_valn = y_valn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cpu\n",
      "cpu\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(X_train.device)\n",
    "print(y_train.device)\n",
    "print(X_valn.device)\n",
    "print(y_valn.device)\n",
    "print(X_test.device)\n",
    "print(y_test.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40157, 128, 128, 1])\n",
      "torch.Size([40157])\n",
      "torch.Size([7087, 128, 128, 1])\n",
      "torch.Size([7087])\n",
      "torch.Size([15748, 128, 128, 1])\n",
      "torch.Size([15748])\n",
      "Wall time: 2.18 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valn.shape)\n",
    "print(y_valn.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iteration over a 0-d tensor'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m             warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\n",
      "\u001b[1;31mTypeError\u001b[0m: iteration over a 0-d tensor"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_correct = []\n",
    "val_correct = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    for b, (X_trn, y_trn) in zip(X_train, y_train):\n",
    "        b += 1\n",
    "        \n",
    "        y_pred = model(X_trn)\n",
    "        loss = criterion(y_pred, y_trn)\n",
    "        \n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_trn).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if b % 600 == 0:\n",
    "            print(f\"EPOCH: {i} BATCH: {b} LOSS: {loss.item()}\")\n",
    "    \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in zip(X_valn, y_valn):\n",
    "\n",
    "            y_val = model(X_test)\n",
    "\n",
    "            predicted = torch.max(y_val.data, 1)[1]\n",
    "            tst_corr = (predicted == y_test).sum()\n",
    "                \n",
    "    loss = criterion(y_val, y_test)\n",
    "    val_losses.append(loss)\n",
    "    val_correct.append(tst_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 100 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x222cbcb6f70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('LOSS AT EPOCH')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
